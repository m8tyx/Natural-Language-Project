{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "# üìä Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# üåê Scraping Google Play Store\n",
    "from google_play_scraper import reviews, Sort\n",
    "\n",
    "# üìù NLP - NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ‚ö° NLP - spaCy\n",
    "import spacy\n",
    "\n",
    "# ü§ñ Machine Learning tools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f572524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d90de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total collected: 4273 reviews\n"
     ]
    }
   ],
   "source": [
    "package_name = 'com.cygames.umamusume'\n",
    "\n",
    "# --- Scraping ---\n",
    "# Ambil 2000 review terbaru\n",
    "newest_reviews, _ = reviews(\n",
    "    package_name,\n",
    "    lang='en',\n",
    "    country='gb',\n",
    "    sort=Sort.NEWEST,\n",
    "    count=4000\n",
    ")\n",
    "\n",
    "# Ambil 1000 review paling helpful\n",
    "helpful_reviews, _ = reviews(\n",
    "    package_name,\n",
    "    lang='en',\n",
    "    country='gb',\n",
    "    sort=Sort.MOST_RELEVANT,\n",
    "    count=1000\n",
    ")\n",
    "\n",
    "# --- Gabungkan hasil scraping ---\n",
    "all_reviews = newest_reviews + helpful_reviews\n",
    "df = pd.DataFrame(all_reviews)\n",
    "# Hapus duplikat (jika ada)\n",
    "df = df.drop_duplicates(subset='reviewId').reset_index(drop=True)\n",
    "# Pilih kolom penting\n",
    "df = df[['reviewId', 'score', 'content', 'at', 'thumbsUpCount']]\n",
    "# --- Simpan ke CSV ---\n",
    "df.to_csv(\"umamusume_reviews_en.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Total collected: {len(df)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26827b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>score</th>\n",
       "      <th>content</th>\n",
       "      <th>at</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8097847a-9292-4f4e-be23-04a82ee69d6e</td>\n",
       "      <td>2</td>\n",
       "      <td>it keeps getting stuck on the loading screen a...</td>\n",
       "      <td>2025-09-13 15:33:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9f85c62-4363-40eb-b70a-edc298cfcfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>update mid september: i dropped a few bucks fo...</td>\n",
       "      <td>2025-09-13 13:52:23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b434889-3a41-4e01-a4b7-5ad9a9189b53</td>\n",
       "      <td>5</td>\n",
       "      <td>The best</td>\n",
       "      <td>2025-09-13 12:49:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df496990-9ff0-4a22-be36-567eef25a980</td>\n",
       "      <td>5</td>\n",
       "      <td>Goldshi Goldshi Goldshi</td>\n",
       "      <td>2025-09-13 12:42:18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49a65a02-7d25-4689-8b4f-c6a38446cc3e</td>\n",
       "      <td>1</td>\n",
       "      <td>The game has too many moving parts. Tutorial w...</td>\n",
       "      <td>2025-09-13 12:29:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId  score  \\\n",
       "0  8097847a-9292-4f4e-be23-04a82ee69d6e      2   \n",
       "1  f9f85c62-4363-40eb-b70a-edc298cfcfbc      1   \n",
       "2  3b434889-3a41-4e01-a4b7-5ad9a9189b53      5   \n",
       "3  df496990-9ff0-4a22-be36-567eef25a980      5   \n",
       "4  49a65a02-7d25-4689-8b4f-c6a38446cc3e      1   \n",
       "\n",
       "                                             content                  at  \\\n",
       "0  it keeps getting stuck on the loading screen a... 2025-09-13 15:33:17   \n",
       "1  update mid september: i dropped a few bucks fo... 2025-09-13 13:52:23   \n",
       "2                                           The best 2025-09-13 12:49:22   \n",
       "3                            Goldshi Goldshi Goldshi 2025-09-13 12:42:18   \n",
       "4  The game has too many moving parts. Tutorial w... 2025-09-13 12:29:04   \n",
       "\n",
       "   thumbsUpCount  \n",
       "0              0  \n",
       "1              6  \n",
       "2              0  \n",
       "3              0  \n",
       "4              1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan lima baris pertama dari DataFrame app_reviews_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f35669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4273 entries, 0 to 4272\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   reviewId       4273 non-null   object        \n",
      " 1   score          4273 non-null   int64         \n",
      " 2   content        4273 non-null   object        \n",
      " 3   at             4273 non-null   datetime64[ns]\n",
      " 4   thumbsUpCount  4273 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 167.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2c524d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm free to play but still got good gacha attempts laugh out loud\n"
     ]
    }
   ],
   "source": [
    "# 1. Cleaning\n",
    "def cleaningText(text):\n",
    "    text = re.sub(r'[0-9]+', '', text)          # hapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)         # hapus karakter selain huruf/angka\n",
    "    \n",
    "    text = text.replace('\\n', ' ')  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  \n",
    "    text = text.strip(' ')  \n",
    "    return text\n",
    "\n",
    "# 2. Casefolding\n",
    "def casefoldingText(text):\n",
    "    return text.lower()\n",
    "\n",
    "# 3. Tokenizing\n",
    "def tokenizingText(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# 4. Stopwords Filtering\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def filteringText(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# 5. Slang Normalization\n",
    "# Fungsi untuk baca slang dari file txt\n",
    "def load_slang_dict(filepath=\"slang.txt\"):\n",
    "    slang_dict = {}\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:  # pastikan format benar\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                slang_dict[key.strip().lower()] = value.strip()\n",
    "    return slang_dict\n",
    "\n",
    "# Fungsi normalisasi teks\n",
    "def normalize_text(text, slang_dict):\n",
    "    words = text.split()\n",
    "    normalized = [slang_dict.get(w.lower(), w) for w in words]\n",
    "    return \" \".join(normalized)\n",
    "\n",
    "# üî• Coba pakai\n",
    "slang_dict = load_slang_dict(\"slang.txt\")\n",
    "\n",
    "sample = \"I'm f2p but still got good pulls lol\"\n",
    "print(normalize_text(sample, slang_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
